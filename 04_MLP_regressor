"""
Multi-Layer Perceptron Neural Network for Albedo Prediction on Svalbard Glaciers

This script implements a deep learning approach to glacier albedo prediction using
Multi-Layer Perceptron neural networks. Tests whether non-linear relationships
between meteorological variables and albedo provide superior predictive performance
compared to linear regression baselines.

Scientific Motivation:
- Glacier albedo involves complex, non-linear processes (phase transitions, feedbacks)
- Neural networks can capture threshold effects and feature interactions
- Provides benchmark for maximum achievable prediction accuracy
- Model-agnostic feature importance through permutation analysis

Model Architecture:
- Multi-Layer Perceptron with hidden layers (100-50 neurons)
- ReLU activation for non-linear learning
- Adam optimizer with early stopping
- L2 regularization to prevent overfitting
- Feature standardization for optimal training

Dependencies: pandas, numpy, scikit-learn, matplotlib
"""

import pandas as pd
import numpy as np
from pathlib import Path
from sklearn.neural_network import MLPRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import r2_score, mean_squared_error
from sklearn.impute import SimpleImputer
from sklearn.model_selection import GridSearchCV
from sklearn.inspection import permutation_importance
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
import warnings
warnings.filterwarnings('ignore', category=FutureWarning)

def load_and_combine_data(train_files, test_files):
    """
    Load and combine meteorological datasets for neural network training.
    
    Neural networks require substantial data volumes for effective training.
    Includes validation for data sufficiency and quality control.
    
    Parameters:
    train_files (list): Training dataset file paths
    test_files (list): Testing dataset file paths
    
    Returns:
    tuple: (train_df, test_df) combined datasets
    """
    print("\n" + "="*60)
    print("LOADING DATA FOR NEURAL NETWORK TRAINING")
    print("="*60)
    
    # Load training datasets with validation
    train_dfs = []
    for file_path in train_files:
        try:
            df = pd.read_csv(file_path)
            
            # Neural network data quality checks
            if len(df) < 50:
                print(f"⚠ Warning: Small dataset in {file_path} ({len(df)} samples)")
            
            # Check for extreme outliers
            numeric_cols = df.select_dtypes(include=[np.number]).columns
            for col in ['TC', 'albedo', 'pdd']:
                if col in numeric_cols:
                    q99, q01 = df[col].quantile(0.99), df[col].quantile(0.01)
                    outliers = ((df[col] > q99) | (df[col] < q01)).sum()
                    if outliers > len(df) * 0.05:
                        print(f"  ⚠ High outlier rate in {col}: {outliers}/{len(df)} ({outliers/len(df)*100:.1f}%)")
            
            train_dfs.append(df)
            print(f"✓ Loaded training: {file_path} ({len(df)} samples)")
            
        except FileNotFoundError:
            print(f"✗ Training file not found: {file_path}")
        except Exception as e:
            print(f"✗ Error loading: {file_path}: {e}")
    
    # Load testing datasets
    test_dfs = []
    for file_path in test_files:
        try:
            df = pd.read_csv(file_path)
            test_dfs.append(df)
            print(f"✓ Loaded testing: {file_path} ({len(df)} samples)")
        except FileNotFoundError:
            print(f"✗ Testing file not found: {file_path}")
        except Exception as e:
            print(f"✗ Error loading: {file_path}: {e}")
    
    # Combine datasets
    train_combined = pd.concat(train_dfs, ignore_index=True) if train_dfs else pd.DataFrame()
    test_combined = pd.concat(test_dfs, ignore_index=True) if test_dfs else pd.DataFrame()
    
    print(f"\nNeural Network Dataset Assessment:")
    print(f"  Training samples: {len(train_combined)}")
    print(f"  Testing samples: {len(test_combined)}")
    
    # Data sufficiency assessment
    if len(train_combined) < 500:
        print(f"  ⚠ WARNING: Limited training data for neural networks")
    elif len(train_combined) < 1000:
        print(f"  ⚠ CAUTION: Moderate training data - use regularization")
    else:
        print(f"  ✓ GOOD: Sufficient training data for neural networks")
    
    return train_combined, test_combined

def filter_season(df, year_col='year', doy_col='day_of_year'):
    """
    Apply seasonal filtering optimized for neural network training.
    
    Focuses on extended ablation season for maximum signal-to-noise ratio
    and optimal albedo-meteorology relationship learning.
    
    Parameters:
    df (pd.DataFrame): Input dataset
    year_col (str): Year column name
    doy_col (str): Day of year column name
    
    Returns:
    pd.DataFrame: Seasonally filtered dataset
    """
    spring_start_doy = 98   # April 8 - onset of dynamic albedo variability
    end_date_doy = 247      # September 4 - end of primary signal period
    
    # Apply seasonal mask
    season_mask = (df[doy_col] >= spring_start_doy) & (df[doy_col] <= end_date_doy)
    filtered_df = df[season_mask].copy()
    
    print(f"\nNeural Network Seasonal Filtering:")
    print(f"  Original: {len(df)} → Filtered: {len(filtered_df)} samples ({len(filtered_df)/len(df)*100:.1f}%)")
    print(f"  Season focus: High signal-to-noise period (Day {spring_start_doy}-{end_date_doy})")
    
    # Analyze data characteristics for neural network training
    if len(filtered_df) > 0 and 'albedo' in filtered_df.columns:
        albedo_stats = filtered_df['albedo'].describe()
        print(f"  Albedo range: {albedo_stats['min']:.3f} to {albedo_stats['max']:.3f}")
        print(f"  Albedo variance: {albedo_stats['std']:.3f} (good variance aids NN training)")
    
    return filtered_df

def prepare_data(train_files, test_files):
    """
    Comprehensive data preparation for neural network training.
    
    Handles complete workflow from raw data to neural network-ready matrices:
    1. Load and validate datasets
    2. Apply seasonal filtering
    3. Define feature set for neural network learning
    4. Handle missing values appropriately
    
    Parameters:
    train_files (list): Training data paths
    test_files (list): Testing data paths
    
    Returns:
    tuple: X_train, X_test, y_train, y_test, test_df (cleaned datasets)
    """
    print("\n" + "="*60)
    print("NEURAL NETWORK DATA PREPARATION PIPELINE")
    print("="*60)
    
    # Load datasets with neural network validation
    train_df, test_df = load_and_combine_data(train_files, test_files)
    
    # Apply seasonal filtering for neural network optimization
    train_df = filter_season(train_df)
    test_df = filter_season(test_df)
    
    # Define neural network feature set
    feature_cols = [
        'TC',                   # Temperature: continuous, high-impact variable
        'pdd',                  # Positive degree days: cumulative thermal info
        'day_of_year',          # Seasonal patterns: cyclical information
        'snowfall_probability'  # Precipitation proxy: probability-based feature
    ]
    
    print(f"\nNeural Network Feature Set:")
    for i, feature in enumerate(feature_cols, 1):
        if feature == 'TC':
            print(f"  {i}. {feature} ← Primary thermal driver (continuous)")
        elif feature == 'pdd':
            print(f"  {i}. {feature} ← Cumulative thermal history")
        elif feature == 'snowfall_probability':
            print(f"  {i}. {feature} ← Precipitation processes")
        else:
            print(f"  {i}. {feature} ← Seasonal patterns")
    
    # Extract features and targets
    X_train = train_df[feature_cols]
    y_train = train_df['albedo']
    X_test = test_df[feature_cols]
    y_test = test_df['albedo']
    
    # Neural network-appropriate missing value imputation
    feature_imputer = SimpleImputer(strategy='mean')
    target_imputer = SimpleImputer(strategy='mean')
    
    print(f"\nApplying neural network-appropriate imputation...")
    X_train_clean = pd.DataFrame(
        feature_imputer.fit_transform(X_train),
        columns=X_train.columns, index=X_train.index
    )
    X_test_clean = pd.DataFrame(
        feature_imputer.transform(X_test),
        columns=X_test.columns, index=X_test.index
    )
    
    y_train_clean = pd.Series(
        target_imputer.fit_transform(y_train.values.reshape(-1, 1)).ravel(),
        index=y_train.index
    )
    y_test_clean = pd.Series(
        target_imputer.transform(y_test.values.reshape(-1, 1)).ravel(),
        index=y_test.index
    )
    
    # Data quality assessment
    print(f"\nNeural Network Data Quality:")
    print(f"  Training samples: {len(X_train_clean)}")
    print(f"  Testing samples: {len(X_test_clean)}")
    
    # Feature distribution analysis
    print(f"\nFeature Distribution Analysis:")
    for feature in feature_cols:
        if feature in X_train_clean.columns:
            stats = X_train_clean[feature].describe()
            feature_range = stats['max'] - stats['min']
            
            print(f"  {feature}: range {stats['min']:.3f} to {stats['max']:.3f}")
            if feature_range > 1000:
                print(f"    ⚠ Large range - standardization essential")
            elif feature_range < 0.01:
                print(f"    ⚠ Small range - may need feature engineering")
            else:
                print(f"    ✓ Good range for neural networks")
    
    # Target variable analysis
    target_stats = y_train_clean.describe()
    print(f"\nTarget Variable (Albedo):")
    print(f"  Range: {target_stats['min']:.3f} to {target_stats['max']:.3f}")
    print(f"  Variance: {target_stats['std']:.3f} {'✓ Good' if target_stats['std'] > 0.05 else '⚠ Low'}")
    
    return X_train_clean, X_test_clean, y_train_clean, y_test_clean, test_df

def train_and_evaluate_mlp(X_train, X_test, y_train, y_test, test_data):
    """
    Train and evaluate Multi-Layer Perceptron for albedo prediction.
    
    Implements comprehensive neural network pipeline:
    - Feature standardization for optimal convergence
    - MLP architecture designed for glaciological regression
    - Early stopping and regularization to prevent overfitting
    - Comprehensive performance evaluation
    
    Parameters:
    X_train, X_test (pd.DataFrame): Feature matrices
    y_train, y_test (pd.Series): Target vectors
    test_data (pd.DataFrame): Original test data for analysis
    
    Returns:
    tuple: model, scaler, predictions, metrics
    """
    print("\n" + "="*60)
    print("NEURAL NETWORK TRAINING AND EVALUATION")
    print("="*60)
    
    # Feature standardization for neural network optimization
    print("Applying feature standardization...")
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    # Verify standardization
    print(f"Standardization validation:")
    print(f"  Training features mean: {X_train_scaled.mean(axis=0).round(3)}")
    print(f"  Training features std: {X_train_scaled.std(axis=0).round(3)}")
    
    # Configure Multi-Layer Perceptron architecture
    mlp = MLPRegressor(
        hidden_layer_sizes=(100, 50),    # Two hidden layers: 100 → 50 neurons
        activation='relu',               # ReLU for non-linear learning
        solver='adam',                   # Adam optimizer
        alpha=0.0001,                   # L2 regularization
        max_iter=1000,                  # Maximum iterations
        early_stopping=True,            # Prevent overfitting
        validation_fraction=0.1,        # 10% validation split
        n_iter_no_change=10,           # Early stopping patience
        random_state=42                 # Reproducible results
    )
    
    print(f"\nNeural Network Architecture:")
    print(f"  Input layer: {X_train.shape[1]} features")
    print(f"  Hidden layer 1: 100 neurons (ReLU)")
    print(f"  Hidden layer 2: 50 neurons (ReLU)")
    print(f"  Output layer: 1 neuron (linear)")
    print(f"  Total parameters: ~{(X_train.shape[1] * 100) + (100 * 50) + (50 * 1):,}")
    
    print(f"\nTraining Configuration:")
    print(f"  Optimizer: Adam, Regularization: L2 (α=0.0001)")
    print(f"  Early stopping: Enabled (patience=10)")
    
    # Train neural network
    print(f"\nTraining neural network...")
    print(f"  [Training in progress - may take 30-60 seconds...]")
    
    mlp.fit(X_train_scaled, y_train)
    
    # Training results
    print(f"\nTraining Results:")
    print(f"  Iterations: {mlp.n_iter_}")
    print(f"  Final loss: {mlp.loss_:.6f}")
    print(f"  Convergence: {'✓ Converged' if mlp.n_iter_ < 1000 else '⚠ Max iterations'}")
    
    # Generate predictions
    print(f"Generating predictions...")
    y_pred = mlp.predict(X_test_scaled)
    
    # Calculate performance metrics
    r2 = r2_score(y_test, y_pred)
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    mae = np.mean(np.abs(y_test - y_pred))
    
    print(f"\nNeural Network Performance:")
    print(f"  R² Score: {r2:.3f}")
    print(f"  RMSE: {rmse:.3f}")
    print(f"  MAE: {mae:.3f}")
    
    # Performance assessment
    performance = ("EXCELLENT" if r2 > 0.8 else "GOOD" if r2 > 0.6 else 
                  "MODERATE" if r2 > 0.4 else "POOR")
    print(f"  Performance Grade: {performance}")
    
    # Station-specific validation
    station_metrics = {}
    print(f"\nStation-Specific Performance:")
    
    for station in test_data['station'].unique():
        station_mask = test_data['station'] == station
        station_y_test = y_test[station_mask]
        station_y_pred = y_pred[station_mask]
        
        if len(station_y_test) > 1:
            station_r2 = r2_score(station_y_test, station_y_pred)
            station_rmse = np.sqrt(mean_squared_error(station_y_test, station_y_pred))
            station_mae = np.mean(np.abs(station_y_test - station_y_pred))
            
            station_metrics[station] = {
                'R2': station_r2, 'RMSE': station_rmse, 'MAE': station_mae,
                'n_samples': len(station_y_test)
            }
            
            grade = ("Excellent" if station_r2 > 0.7 else "Good" if station_r2 > 0.5 else "Moderate")
            print(f"  {station}: R² = {station_r2:.3f} ({grade}), n = {len(station_y_test)}")
    
    # Placeholder for feature importance (calculated separately)
    feature_importance = {}
    normalized_importance = {}
    
    return mlp, scaler, y_pred, r2, rmse, station_metrics, feature_importance, normalized_importance

def calculate_feature_importance(model, X_test_scaled, y_test, feature_names):
    """
    Calculate neural network feature importance using permutation importance.
    
    Provides model-agnostic approach to understand feature contributions
    through systematic feature permutation and performance degradation analysis.
    
    Parameters:
    model (MLPRegressor): Trained neural network
    X_test_scaled (array): Standardized test features
    y_test (array): Test targets
    feature_names (list): Feature names for labeling
    
    Returns:
    tuple: (feature_importance, normalized_importance)
    """
    print("\n" + "="*50)
    print("NEURAL NETWORK FEATURE IMPORTANCE ANALYSIS")
    print("="*50)
    
    print("Calculating permutation importance...")
    print("  Method: Permutation-based feature importance")
    print("  Repetitions: 10 (for statistical robustness)")
    print("  [Processing - may take 30-60 seconds...]")
    
    # Calculate permutation importance
    perm_importance = permutation_importance(
        model, X_test_scaled, y_test, 
        n_repeats=10, random_state=42, scoring='r2'
    )
    
    # Extract importance statistics
    importance_means = perm_importance.importances_mean
    importance_stds = perm_importance.importances_std
    
    # Create dictionaries
    feature_importance = dict(zip(feature_names, importance_means))
    importance_uncertainties = dict(zip(feature_names, importance_stds))
    
    # Calculate normalized importance
    total_importance = np.sum(np.maximum(importance_means, 0))
    if total_importance > 0:
        normalized_importance = {
            feature: max(importance, 0) / total_importance 
            for feature, importance in feature_importance.items()
        }
    else:
        normalized_importance = {feature: 1.0/len(feature_names) for feature in feature_names}
    
    # Display results
    print(f"\nPermutation Importance Results:")
    print(f"{'Feature':<25} {'Importance':<12} {'Std':<8} {'Normalized':<12}")
    print(f"{'-'*65}")
    
    sorted_features = sorted(feature_importance.items(), key=lambda x: x[1], reverse=True)
    
    for feature, importance in sorted_features:
        std = importance_uncertainties[feature]
        normalized = normalized_importance[feature]
        
        # Interpret importance level
        interp = ("DOMINANT" if normalized > 0.4 else "HIGH" if normalized > 0.25 else 
                 "MODERATE" if normalized > 0.15 else "LOW" if normalized > 0.05 else "MINIMAL")
        
        print(f"{feature:<25} {importance:>8.3f}    {std:>6.3f}   {normalized:>8.1%}     {interp}")
    
    # Statistical significance assessment
    print(f"\nStatistical Assessment:")
    significant_features = []
    for feature, importance in feature_importance.items():
        std = importance_uncertainties[feature]
        if importance > 2 * std:
            significant_features.append(feature)
            print(f"  ✓ {feature}: Statistically significant")
        else:
            print(f"  ~ {feature}: Not statistically significant")
    
    print(f"\nFeature Importance Summary:")
    print(f"  Significant features: {len(significant_features)}/{len(feature_names)}")
    print(f"  Most important: {sorted_features[0][0]} ({normalized_importance[sorted_features[0][0]]:.1%})")
    
    return feature_importance, normalized_importance

def plot_predicted_vs_measured(y_test, y_pred, test_data):
    """
    Create diagnostic scatter plot for neural network albedo predictions.
    
    Features comprehensive performance assessment with station-wise analysis,
    perfect prediction reference, and confidence bands.
    
    Parameters:
    y_test (array): Observed albedo values
    y_pred (array): Neural network predictions
    test_data (pd.DataFrame): Test dataset with station info
    """
    plt.figure(figsize=(12, 9))
    
    # Station-wise plotting with enhanced styling
    colors = ['#2E86AB', '#A23B72', '#F18F01', '#C73E1D', '#6A994E', '#8E44AD']
    markers = ['o', 's', '^', 'D', 'v', 'P']
    
    for i, station in enumerate(test_data['station'].unique()):
        station_mask = test_data['station'] == station
        color = colors[i % len(colors)]
        marker = markers[i % len(markers)]
        
        plt.scatter(y_test[station_mask], y_pred[station_mask], 
                   alpha=0.7, s=80, color=color, marker=marker,
                   label=f'{station.upper()}', 
                   edgecolors='white', linewidth=1.5)
    
    # Perfect prediction reference line
    min_val = min(min(y_test), min(y_pred))
    max_val = max(max(y_test), max(y_pred))
    line_range = np.linspace(min_val, max_val, 100)
    plt.plot(line_range, line_range, 'k--', alpha=0.8, linewidth=3, 
             label='Perfect Prediction (1:1)', zorder=1)
    
    # Performance metrics
    r2_overall = r2_score(y_test, y_pred)
    rmse_overall = np.sqrt(mean_squared_error(y_test, y_pred))
    mae_overall = np.mean(np.abs(y_test - y_pred))
    
    textstr = (f'Multi-Layer Perceptron Neural Network\n'
               f'R² = {r2_overall:.3f}\n'
               f'RMSE = {rmse_overall:.3f}\n'
               f'MAE = {mae_overall:.3f}\n'
               f'Samples = {len(y_test)}')
    
    props = dict(boxstyle='round,pad=0.5', facecolor='lightgreen', alpha=0.8)
    plt.text(0.05, 0.95, textstr, transform=plt.gca().transAxes, 
             fontsize=12, fontweight='bold', verticalalignment='top', bbox=props)
    
    # Add confidence bands
    residuals = y_test - y_pred
    residual_std = np.std(residuals)
    
    plt.fill_between(line_range, line_range - residual_std, line_range + residual_std,
                     alpha=0.1, color='gray', label='±1σ residual band')
    
    # Formatting
    plt.xlabel('Measured Albedo', fontweight='bold', fontsize=14)
    plt.ylabel('Neural Network Predicted Albedo', fontweight='bold', fontsize=14)
    plt.title('Neural Network Albedo Prediction Validation\n'
              'Multi-Layer Perceptron Non-Linear Approach (2011 Test Data)', 
              fontweight='bold', fontsize=16)
    
    plt.legend(loc='lower right', framealpha=0.9)
    plt.grid(True, alpha=0.3)
    plt.axis('equal')
    
    margin = (max_val - min_val) * 0.05
    plt.xlim(min_val - margin, max_val + margin)
    plt.ylim(min_val - margin, max_val + margin)
    
    plt.tight_layout()
    plt.show()

def plot_feature_importance(feature_importance):
    """
    Visualize neural network feature importance with process-based color coding.
    
    Shows relative importance of meteorological variables as learned by
    the neural network with enhanced styling for publication.
    
    Parameters:
    feature_importance (dict): Permutation importance values
    """
    plt.figure(figsize=(12, 8))
    
    # Prepare plotting data
    importance_df = pd.DataFrame({
        'Feature': list(feature_importance.keys()),
        'Importance': list(feature_importance.values())
    })
    
    # Sort by importance
    importance_df = importance_df.sort_values('Importance', ascending=True)
    
    # Process-based color scheme
    colors = []
    for feature in importance_df['Feature']:
        if feature == 'TC':
            colors.append('#FF6B35')  # Orange-red for temperature
        elif feature == 'pdd':
            colors.append('#FF8C42')  # Light orange for thermal history
        elif feature == 'snowfall_probability':
            colors.append('#004E89')  # Blue for precipitation
        else:  # day_of_year
            colors.append('#7209B7')  # Purple for seasonal
    
    # Create horizontal bar plot
    bars = plt.barh(importance_df['Feature'], importance_df['Importance'], 
                   color=colors, alpha=0.8, edgecolor='white', linewidth=2)
    
    # Add importance annotations
    for i, (feature, importance) in enumerate(zip(importance_df['Feature'], importance_df['Importance'])):
        plt.text(importance + 0.001, i, f'{importance:.3f}', 
                ha='left', va='center', fontweight='bold', fontsize=11)
    
    # Formatting
    plt.xlabel('Permutation Importance\n(R² degradation when feature randomized)', 
               fontweight='bold', fontsize=12)
    plt.ylabel('Meteorological Features', fontweight='bold', fontsize=12)
    plt.title('Neural Network Feature Importance Analysis\n'
              'Multi-Layer Perceptron: Process Contributions', 
              fontweight='bold', fontsize=14)
    
    plt.grid(True, alpha=0.3, axis='x')
    
    # Custom legend for process types
    from matplotlib.patches import Patch
    legend_elements = [
        Patch(facecolor='#FF6B35', alpha=0.8, label='Temperature'),
        Patch(facecolor='#FF8C42', alpha=0.8, label='Thermal History'),
        Patch(facecolor='#004E89', alpha=0.8, label='Precipitation'),
        Patch(facecolor='#7209B7', alpha=0.8, label='Seasonal')
    ]
    plt.legend(handles=legend_elements, loc='lower right')
    
    # Add interpretation
    max_importance = max(importance_df['Importance'])
    dominant_feature = importance_df.loc[importance_df['Importance'].idxmax(), 'Feature']
    
    interp_text = f"Most Important: {dominant_feature}\n(Importance: {max_importance:.3f})"
    plt.text(0.02, 0.98, interp_text, transform=plt.gca().transAxes,
             fontsize=11, verticalalignment='top', fontweight='bold',
             bbox=dict(boxstyle='round,pad=0.3', facecolor='yellow', alpha=0.7))
    
    plt.tight_layout()
    plt.show()

def plot_station_time_series(station_name, test_data, y_test, y_pred):
    """
    Create temporal validation plot for neural network predictions.
    
    Shows measured vs. predicted albedo evolution with performance metrics,
    prediction uncertainty bands, and monthly temporal reference.
    
    Parameters:
    station_name (str): Station identifier
    test_data (pd.DataFrame): Original temporal dataset
    y_test (array): Observed albedo values
    y_pred (array): Neural network predictions
    """
    # Extract station data
    station_mask = test_data['station'] == station_name
    
    if not station_mask.any():
        print(f"Warning: No data found for station {station_name}")
        return
    
    station_data = test_data[station_mask].copy()
    station_measured = y_test[station_mask]
    station_predicted = y_pred[station_mask]
    
    # Sort by temporal order
    sort_indices = np.argsort(station_data['day_of_year'].values)
    days_sorted = station_data['day_of_year'].values[sort_indices]
    measured_sorted = station_measured.values[sort_indices]
    predicted_sorted = station_predicted[sort_indices]
    
    # Calculate performance metrics
    station_r2 = r2_score(station_measured, station_predicted)
    station_rmse = np.sqrt(mean_squared_error(station_measured, station_predicted))
    station_mae = np.mean(np.abs(station_measured - station_predicted))
    
    # Create time series plot
    plt.figure(figsize=(15, 9))
    
    # Plot measured and predicted albedo
    plt.plot(days_sorted, measured_sorted, 'b-', linewidth=3.5, 
             label='Measured Albedo', alpha=0.9, marker='o', markersize=6,
             markerfacecolor='lightblue', markeredgecolor='blue', markeredgewidth=2)
    
    plt.plot(days_sorted, predicted_sorted, 'r--', linewidth=3, 
             label='Neural Network Prediction', alpha=0.9, marker='s', markersize=5,
             markerfacecolor='lightcoral', markeredgecolor='darkred', markeredgewidth=1.5)
    
    # Add prediction error visualization
    plt.fill_between(days_sorted, measured_sorted, predicted_sorted, 
                     alpha=0.25, color='gray', label='Prediction Error')
    
    # Add uncertainty bands
    residuals = measured_sorted - predicted_sorted
    residual_std = np.std(residuals)
    
    plt.fill_between(days_sorted, predicted_sorted - residual_std, predicted_sorted + residual_std,
                     alpha=0.15, color='red', label='Neural Network Uncertainty (±1σ)')
    
    # Performance annotation
    textstr = (f'Neural Network Performance: {station_name.upper()}\n'
               f'Architecture: MLP (100-50 neurons)\n'
               f'R² = {station_r2:.3f}\n'
               f'RMSE = {station_rmse:.3f}\n'
               f'MAE = {station_mae:.3f}\n'
               f'Samples = {len(station_measured)}')
    
    props = dict(boxstyle='round,pad=0.5', facecolor='lightcyan', alpha=0.9)
    plt.text(0.02, 0.98, textstr, transform=plt.gca().transAxes, fontsize=12,
             verticalalignment='top', bbox=props, fontweight='bold')
    
    # Formatting
    plt.xlabel('Day of Year', fontweight='bold', fontsize=14)
    plt.ylabel('Surface Albedo', fontweight='bold', fontsize=14)
    plt.title(f'Neural Network Albedo Prediction: {station_name.upper()}\n'
              f'Multi-Layer Perceptron Validation (2011)', 
              fontweight='bold', fontsize=16)
    
    plt.legend(loc='upper right', framealpha=0.9)
    plt.grid(True, alpha=0.3)
    plt.ylim(0, 1)
    
    # Add monthly reference
    month_days = [98, 121, 152, 182, 213, 244]
    month_labels = ['Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep']
    
    valid_months = [(day, label) for day, label in zip(month_days, month_labels) 
                   if min(days_sorted) <= day <= max(days_sorted)]
    
    if valid_months:
        valid_days, valid_labels = zip(*valid_months)
        plt.xticks(valid_days, valid_labels)
        
        # Add month separators
        for day in valid_days:
            plt.axvline(x=day, color='gray', linestyle=':', alpha=0.6)
    
    # Performance assessment indicator
    perf_color = ('green' if station_r2 > 0.8 else 'orange' if station_r2 > 0.6 else 
                 'yellow' if station_r2 > 0.4 else 'red')
    perf_text = ('EXCELLENT' if station_r2 > 0.8 else 'GOOD' if station_r2 > 0.6 else 
                'MODERATE' if station_r2 > 0.4 else 'POOR')
    
    plt.text(0.98, 0.02, f'Performance: {perf_text}', transform=plt.gca().transAxes,
             fontsize=14, fontweight='bold', ha='right', va='bottom',
             bbox=dict(boxstyle='round,pad=0.3', facecolor=perf_color, alpha=0.7))
    
    plt.tight_layout()
    plt.show()

def main():
    """
    Main execution function for neural network albedo prediction analysis.
    
    Tests hypothesis that neural networks can capture non-linear relationships
    between meteorological variables and glacier albedo, providing superior
    predictive performance compared to linear regression baselines.
    
    Workflow:
    1. Load datasets with neural network validation
    2. Train MLP with comprehensive architecture
    3. Evaluate non-linear learning capability
    4. Calculate permutation-based feature importance
    5. Generate publication-ready visualizations
    6. Assess model complexity vs. performance trade-offs
    """
    print("="*70)
    print("NEURAL NETWORK GLACIER ALBEDO PREDICTION")
    print("Multi-Layer Perceptron for Non-Linear Relationship Discovery")
    print("="*70)
    print(f"Analysis started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # Research hypothesis
    print(f"\nRESEARCH HYPOTHESIS:")
    print(f"  Glacier albedo involves complex, non-linear relationships that")
    print(f"  cannot be captured by linear models. Neural networks can discover")
    print(f"  these patterns and provide superior predictive performance.")
    
    print(f"\nNEURAL NETWORK ADVANTAGES:")
    print(f"  • Non-linear relationship detection (thresholds, interactions)")
    print(f"  • Automatic feature engineering through hidden layers")
    print(f"  • Robust handling of complex meteorological patterns")
    print(f"  • Model-agnostic feature importance assessment")
    
    # Dataset configuration
    # Note: Currently single-station for focused analysis
    train_files = [
        "hans9_2010_processed_with_pdd.csv",      # Primary training data
        # Additional stations available by uncommenting:
        # "hans4_2010_processed_with_pdd.csv",
        # "werenskiold_2012_processed_with_pdd.csv",
    ]
    
    test_files = [
        "hans9_2011_processed_with_pdd.csv",      # Primary testing data
        # Additional stations available by uncommenting:
        # "hans4_2011_processed_with_pdd.csv",
        # "werenskiold_2011_processed_with_pdd.csv"
    ]
    
    print(f"\nDataset Configuration:")
    print(f"  Current: Single-station analysis (hans9)")
    print(f"  Training: 2010 | Testing: 2011 (temporal independence)")
    print(f"  Note: Multi-station analysis available by uncommenting file paths")
    
    # Data preparation
    print(f"\n{'-'*60}")
    print("NEURAL NETWORK DATA PREPARATION")
    print(f"{'-'*60}")
    
    X_train_clean, X_test_clean, y_train_clean, y_test_clean, test_data_clean = prepare_data(
        train_files, test_files
    )
    
    # Validate data availability
    if len(X_train_clean) == 0 or len(X_test_clean) == 0:
        print("ERROR: Insufficient data. Check file paths.")
        return
    
    if len(X_train_clean) < 100:
        print("WARNING: Limited training data for neural networks.")
    
    # Neural network training and evaluation
    mlp, scaler, y_pred, r2, rmse, station_metrics, _, _ = train_and_evaluate_mlp(
        X_train_clean, X_test_clean, y_train_clean, y_test_clean, test_data_clean
    )
    
    # Feature importance analysis
    print(f"\n{'-'*60}")
    print("NEURAL NETWORK INTERPRETABILITY")
    print(f"{'-'*60}")
    
    X_test_scaled = scaler.transform(X_test_clean)
    feature_importance, normalized_importance = calculate_feature_importance(
        mlp, X_test_scaled, y_test_clean, X_train_clean.columns
    )
    
    # Performance assessment
    print(f"\n{'-'*60}")
    print("NEURAL NETWORK PERFORMANCE ASSESSMENT")
    print(f"{'-'*60}")
    
    performance = ("EXCELLENT" if r2 > 0.8 else "GOOD" if r2 > 0.6 else 
                  "MODERATE" if r2 > 0.4 else "POOR")
    
    print(f"Overall Performance:")
    print(f"  R² Score: {r2:.3f}")
    print(f"  RMSE: {rmse:.3f}")
    print(f"  Performance Grade: {performance}")
    
    if r2 > 0.7:
        print(f"  → Neural network demonstrates strong non-linear learning")
    elif r2 > 0.5:
        print(f"  → Neural network shows meaningful predictive capability")
    else:
        print(f"  → Linear models may be sufficient for this application")
    
    # Station-specific results
    if station_metrics:
        print(f"\nSpatial Generalization:")
        for station, metrics in station_metrics.items():
            print(f"  {station}: R² = {metrics['R2']:.3f}, RMSE = {metrics['RMSE']:.3f}")
    
    # Process dominance analysis
    thermal_features = ['TC', 'pdd']
    thermal_importance = sum(normalized_importance.get(f, 0) for f in thermal_features)
    precip_importance = normalized_importance.get('snowfall_probability', 0)
    seasonal_importance = normalized_importance.get('day_of_year', 0)
    
    print(f"\nProcess Dominance (Neural Network Learning):")
    print(f"  Thermal Processes: {thermal_importance:.1%}")
    print(f"  Precipitation Processes: {precip_importance:.1%}")
    print(f"  Seasonal Patterns: {seasonal_importance:.1%}")
    
    # Determine dominant process
    dominant = max([("Thermal", thermal_importance), ("Precipitation", precip_importance), 
                   ("Seasonal", seasonal_importance)], key=lambda x: x[1])
    
    print(f"  → Neural network identifies {dominant[0]} dominance ({dominant[1]:.1%})")
    
    # Generate visualizations
    print(f"\n{'-'*60}")
    print("GENERATING NEURAL NETWORK VISUALIZATIONS")
    print(f"{'-'*60}")
    
    print("Creating predicted vs. measured scatter plot...")
    plot_predicted_vs_measured(y_test_clean, y_pred, test_data_clean)
    
    print("Creating feature importance plot...")
    plot_feature_importance(feature_importance)
    
    print("Creating station-specific time series plots...")
    for station in test_data_clean['station'].unique():
        print(f"  Plotting neural network validation for {station}...")
        plot_station_time_series(station, test_data_clean, y_test_clean, y_pred)
    
    # Research insights and recommendations
    print(f"\n{'-'*60}")
    print("NEURAL NETWORK RESEARCH INSIGHTS")
    print(f"{'-'*60}")
    
    print(f"Non-Linear Relationship Assessment:")
    if r2 > 0.7:
        print(f"  ✓ STRONG evidence for complex albedo-meteorology relationships")
        print(f"  → Neural networks capture significant non-linear patterns")
    elif r2 > 0.5:
        print(f"  ✓ MODERATE evidence for non-linear relationships")
        print(f"  → Neural networks provide meaningful improvements")
    else:
        print(f"  ⚠ LIMITED evidence for complex relationships")
        print(f"  → Linear models may be sufficient")
    
    print(f"\nModel Validation Status:")
    if r2 > 0.6 and len(station_metrics) > 0:
        print(f"  ✓ RECOMMENDED for operational albedo prediction")
        print(f"  → Demonstrates robust non-linear learning capability")
    elif r2 > 0.4:
        print(f"  ✓ PROMISING for research applications")
        print(f"  → Consider ensemble approaches with linear models")
    else:
        print(f"  ⚠ REQUIRES FURTHER DEVELOPMENT")
        print(f"  → Investigate data quality and feature engineering")
    
    print(f"\nResearch Recommendations:")
    print(f"  1. Compare directly with linear regression baselines")
    print(f"  2. Multi-station training for improved generalization")
    print(f"  3. Ensemble methods combining neural networks with linear models")
    print(f"  4. Temporal sequence modeling (LSTM/RNN) for time-series")
    print(f"  5. Physics-informed neural networks with energy balance")
    
    print(f"\nPublication Considerations:")
    print(f"  • Emphasize non-linear relationship discovery capabilities")
    print(f"  • Compare performance improvements over linear baselines")
    print(f"  • Discuss computational requirements vs. accuracy trade-offs")
    print(f"  • Address interpretability through permutation importance")
    
    print(f"\n{'='*70}")
    print(f"Neural network analysis completed: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"{'='*70}")

if __name__ == "__main__":
    """Execute complete neural network albedo prediction analysis."""
    main()
