import ee
import pandas as pd
import numpy as np

def initialize_earth_engine(project_id='ee-dcyran94'):
    """
    Initialize Google Earth Engine for satellite albedo analysis.
    
    Parameters:
    project_id (str): Google Earth Engine project ID
    """
    try:
        ee.Initialize(project=project_id)
        print("✓ Google Earth Engine initialized successfully")
    except Exception as e:
        print(f"❌ Earth Engine initialization failed: {e}")
        print("Please run the authentication setup script first.")
        raise

def define_glacier_geometries():
    """
    Define glacier boundaries for Hansbreen and Werenskioldbreen glaciers.
    Uses circular approximations based on glacier area measurements.
    
    Returns:
    tuple: (hansbreen_geometry, werenskiold_geometry)
    """
    print("Defining glacier geometries...")
    
    # Glacier areas from field measurements (km²)
    hansbreen_area_km2 = 64.21
    werenskiold_area_km2 = 26.72
    
    # Convert to circular geometries (radius in meters)
    hansbreen_radius = np.sqrt(hansbreen_area_km2 / np.pi) * 1000
    werenskiold_radius = np.sqrt(werenskiold_area_km2 / np.pi) * 1000
    
    # Glacier center coordinates (decimal degrees)
    hansbreen_center = [15.627, 77.082]
    werenskiold_center = [15.338, 77.083]
    
    # Create Earth Engine geometries
    hansbreen_ee = ee.Geometry.Point(hansbreen_center).buffer(hansbreen_radius)
    werenskiold_ee = ee.Geometry.Point(werenskiold_center).buffer(werenskiold_radius)
    
    print(f"  Hansbreen: {hansbreen_area_km2} km² (radius: {hansbreen_radius:.0f} m)")
    print(f"  Werenskioldbreen: {werenskiold_area_km2} km² (radius: {werenskiold_radius:.0f} m)")
    
    return hansbreen_ee, werenskiold_ee

def get_landsat_images(target_dates):
    """
    Retrieve Landsat 7 images for specific target dates over Svalbard.
    
    Parameters:
    target_dates (list): List of date strings in 'YYYY-MM-DD' format
    
    Returns:
    ee.ImageCollection: Filtered Landsat image collection
    """
    print(f"Retrieving Landsat images for target dates: {target_dates}")
    
    # Define study area boundary (Svalbard region)
    study_area = ee.Geometry.Rectangle([15.0, 77.0, 16.0, 77.2])
    
    # Get Landsat 7 Surface Reflectance collection
    collection = ee.ImageCollection('LANDSAT/LE07/C02/T1_L2') \
        .filterBounds(study_area) \
        .filter(ee.Filter.inList('DATE_ACQUIRED', target_dates))
    
    # Get basic information about retrieved images
    all_images = collection.getInfo()
    image_count = len(all_images['features'])
    
    print(f"  Retrieved {image_count} Landsat images")
    
    # Display image information
    image_info = []
    for i, img in enumerate(all_images['features']):
        props = img['properties']
        date = props['DATE_ACQUIRED']
        cloud_cover = props.get('CLOUD_COVER', 'N/A')
        image_info.append({'date': date, 'cloud_cover': cloud_cover, 'index': i})
        print(f"    {i+1}. {date} - {cloud_cover}% cloud cover")
    
    return collection, image_info

def define_albedo_algorithms():
    """
    Define multiple broadband albedo calculation algorithms for comparison.
    Each algorithm uses different spectral band coefficients optimized for specific applications.
    """
    
    algorithms_info = {
        'liang': {
            'name': 'Liang (2001)',
            'description': 'Standard broadband albedo algorithm',
            'reference': 'Liang, S. (2001). Narrowband to broadband conversions of land surface albedo',
            'coefficients': {'blue': 0.356, 'green': 0.130, 'red': 0.373, 'nir': 0.085, 'swir1': 0.072, 'swir2': -0.0018}
        },
        'tasumi': {
            'name': 'Tasumi et al. (2008)',
            'description': 'Updated coefficients for improved accuracy',
            'reference': 'Tasumi et al. (2008). At-surface reflectance and albedo from satellite',
            'coefficients': {'blue': 0.254, 'green': 0.149, 'red': 0.147, 'nir': 0.311, 'swir1': 0.103, 'swir2': 0.036}
        },
        'silva': {
            'name': 'Silva et al. (2016)',
            'description': 'Adapted coefficients for glacier surfaces',
            'reference': 'Silva et al. (2016). Satellite-based albedo estimates for glaciers',
            'coefficients': {'blue': 0.300, 'green': 0.277, 'red': 0.233, 'nir': 0.143, 'swir1': 0.036, 'swir2': 0.012}
        },
        'simple': {
            'name': 'Simple visible-NIR',
            'description': 'Simplified approach using visible and near-infrared bands',
            'reference': 'Equal weighting of blue, green, red, and NIR bands',
            'coefficients': {'blue': 0.25, 'green': 0.25, 'red': 0.25, 'nir': 0.25, 'swir1': 0.0, 'swir2': 0.0}
        },
        'knap': {
            'name': 'Knap et al. (1999)',
            'description': 'Specifically developed for snow and ice surfaces',
            'reference': 'Knap et al. (1999). Narrowband to broadband conversion for snow/ice',
            'coefficients': {'blue': 0.726, 'green': 0.0, 'red': 0.322, 'nir': -0.015, 'swir1': 0.581, 'swir2': 0.375}
        }
    }
    
    print("Albedo algorithms defined:")
    for alg_key, alg_info in algorithms_info.items():
        print(f"  {alg_info['name']}: {alg_info['description']}")
    
    return algorithms_info

def calculate_multiple_albedos(image, algorithms_info):
    """
    Calculate albedo using multiple algorithms on a single Landsat image.
    
    Parameters:
    image (ee.Image): Landsat surface reflectance image
    algorithms_info (dict): Dictionary containing algorithm specifications
    
    Returns:
    ee.Image: Image with albedo bands for each algorithm
    """
    
    def apply_scale_factors(img):
        """Apply Landsat Collection 2 surface reflectance scaling factors"""
        optical_bands = img.select(['SR_B1', 'SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B7']) \
                          .multiply(0.0000275).add(-0.2)
        return img.addBands(optical_bands, None, True)
    
    # Apply scaling to convert to reflectance values
    scaled_image = apply_scale_factors(image)
    
    # Extract individual spectral bands
    blue = scaled_image.select('SR_B1')    # Band 1: Blue (0.45-0.52 μm)
    green = scaled_image.select('SR_B2')   # Band 2: Green (0.52-0.60 μm)
    red = scaled_image.select('SR_B3')     # Band 3: Red (0.63-0.69 μm)
    nir = scaled_image.select('SR_B4')     # Band 4: NIR (0.77-0.90 μm)
    swir1 = scaled_image.select('SR_B5')   # Band 5: SWIR1 (1.55-1.75 μm)
    swir2 = scaled_image.select('SR_B7')   # Band 7: SWIR2 (2.09-2.35 μm)
    
    albedo_bands = []
    
    # Calculate albedo for each algorithm
    for alg_key, alg_info in algorithms_info.items():
        coeffs = alg_info['coefficients']
        
        # Apply weighted combination of spectral bands
        if alg_key == 'simple':
            # Special case: simple average of visible and NIR bands
            albedo = blue.add(green).add(red).add(nir).divide(4)
        else:
            # Standard weighted combination
            albedo = blue.multiply(coeffs['blue']) \
                    .add(green.multiply(coeffs['green'])) \
                    .add(red.multiply(coeffs['red'])) \
                    .add(nir.multiply(coeffs['nir'])) \
                    .add(swir1.multiply(coeffs['swir1'])) \
                    .add(swir2.multiply(coeffs['swir2']))
        
        # Clamp values to valid albedo range [0, 1]
        albedo = albedo.clamp(0, 1).rename(f'albedo_{alg_key}')
        albedo_bands.append(albedo)
    
    # Add all albedo bands to the original image
    return scaled_image.addBands(albedo_bands)

def mask_clouds_and_shadows(image):
    """
    Apply enhanced cloud and shadow masking while preserving snow pixels.
    Important for glacier albedo analysis where snow is the target surface.
    
    Parameters:
    image (ee.Image): Landsat image with QA_PIXEL band
    
    Returns:
    ee.Image: Masked image with clouds and shadows removed
    """
    qa = image.select('QA_PIXEL')
    
    # Define bit positions for different quality flags
    cloud_bit = 3      # Cloud bit
    shadow_bit = 4     # Cloud shadow bit
    cirrus_bit = 2     # Cirrus cloud bit
    # Note: We intentionally keep snow pixels (bit 5) for glacier analysis
    
    # Create masks for clear pixels
    cloud_mask = qa.bitwiseAnd(1 << cloud_bit).eq(0)
    shadow_mask = qa.bitwiseAnd(1 << shadow_bit).eq(0)
    cirrus_mask = qa.bitwiseAnd(1 << cirrus_bit).eq(0)
    
    # Combine masks (AND operation requires all conditions to be true)
    clear_mask = cloud_mask.And(shadow_mask).And(cirrus_mask)
    
    return image.updateMask(clear_mask)

def get_glacier_albedo_statistics(image, glacier_geometry, date, cloud_cover, algorithms_info):
    """
    Calculate comprehensive albedo statistics for a glacier using all algorithms.
    
    Parameters:
    image (ee.Image): Landsat image
    glacier_geometry (ee.Geometry): Glacier boundary
    date (str): Image acquisition date
    cloud_cover (float): Cloud cover percentage
    algorithms_info (dict): Algorithm specifications
    
    Returns:
    dict: Statistics for all albedo algorithms
    """
    
    # Apply cloud masking and albedo calculations
    masked_image = mask_clouds_and_shadows(image)
    albedo_image = calculate_multiple_albedos(masked_image, algorithms_info)
    
    # Clip to glacier area
    glacier_image = albedo_image.clip(glacier_geometry)
    
    # Initialize results dictionary
    results = {'date': date, 'cloud_cover': cloud_cover}
    
    # Calculate statistics for each algorithm
    for alg_key in algorithms_info.keys():
        band_name = f'albedo_{alg_key}'
        
        # Calculate mean, standard deviation, and pixel count
        stats = glacier_image.select(band_name).reduceRegion(
            reducer=ee.Reducer.mean().combine(
                ee.Reducer.stdDev(), sharedInputs=True
            ).combine(
                ee.Reducer.count(), sharedInputs=True
            ),
            geometry=glacier_geometry,
            scale=30,  # Landsat pixel size
            maxPixels=1e9
        ).getInfo()
        
        # Store statistics in results
        results[f'{band_name}_mean'] = stats.get(f'{band_name}_mean')
        results[f'{band_name}_std'] = stats.get(f'{band_name}_stdDev')
        results[f'{band_name}_count'] = stats.get(f'{band_name}_count')
    
    return results

def analyze_temporal_changes(df, algorithms_info):
    """
    Analyze temporal changes in albedo between different dates.
    
    Parameters:
    df (pd.DataFrame): DataFrame with albedo statistics
    algorithms_info (dict): Algorithm specifications
    
    Returns:
    dict: Temporal change analysis results
    """
    if len(df) < 2:
        return None
    
    # Sort by date to ensure correct temporal order
    df_sorted = df.sort_values('date')
    
    changes = {}
    
    # Calculate changes between consecutive dates
    for i in range(1, len(df_sorted)):
        earlier_date = df_sorted.iloc[i-1]['date']
        later_date = df_sorted.iloc[i]['date']
        
        date_pair = f"{earlier_date} → {later_date}"
        changes[date_pair] = {}
        
        for alg_key in algorithms_info.keys():
            mean_col = f'albedo_{alg_key}_mean'
            
            earlier_val = df_sorted.iloc[i-1][mean_col]
            later_val = df_sorted.iloc[i][mean_col]
            
            if earlier_val is not None and later_val is not None:
                absolute_change = later_val - earlier_val
                percent_change = (absolute_change / earlier_val) * 100
                
                changes[date_pair][alg_key] = {
                    'absolute': absolute_change,
                    'percent': percent_change
                }
    
    return changes

def display_results(hansbreen_df, werenskiold_df, algorithms_info):
    """
    Display comprehensive results for both glaciers with formatted output.
    
    Parameters:
    hansbreen_df (pd.DataFrame): Hansbreen results
    werenskiold_df (pd.DataFrame): Werenskioldbreen results
    algorithms_info (dict): Algorithm specifications
    """
    
    print("\n" + "="*70)
    print("SATELLITE ALBEDO ANALYSIS RESULTS")
    print("="*70)
    
    # Display results for each glacier
    for df, glacier_name in [(hansbreen_df, 'HANSBREEN'), (werenskiold_df, 'WERENSKIOLDBREEN')]:
        print(f"\n{glacier_name} GLACIER")
        print("="*50)
        
        for _, row in df.iterrows():
            # Check if we have valid data for any algorithm
            has_valid_data = any(row[f'albedo_{alg}_mean'] is not None for alg in algorithms_info.keys())
            
            if has_valid_data:
                print(f"\n{row['date']} (Cloud cover: {row['cloud_cover']}%)")
                print("-" * 45)
                
                for alg_key, alg_info in algorithms_info.items():
                    mean_val = row[f'albedo_{alg_key}_mean']
                    std_val = row[f'albedo_{alg_key}_std']
                    count_val = row[f'albedo_{alg_key}_count']
                    
                    if mean_val is not None:
                        print(f"  {alg_info['name']:<20}: {mean_val:.3f} ± {std_val:.3f} ({count_val} pixels)")

def analyze_algorithm_comparison(hansbreen_df, werenskiold_df, algorithms_info):
    """
    Create detailed comparison between different albedo algorithms.
    
    Parameters:
    hansbreen_df (pd.DataFrame): Hansbreen results
    werenskiold_df (pd.DataFrame): Werenskioldbreen results
    algorithms_info (dict): Algorithm specifications
    
    Returns:
    pd.DataFrame: Comparison table
    """
    
    print("\n" + "="*70)
    print("ALGORITHM COMPARISON ANALYSIS")
    print("="*70)
    
    # Create comparison data
    comparison_data = []
    
    for df, glacier_name in [(hansbreen_df, 'Hansbreen'), (werenskiold_df, 'Werenskioldbreen')]:
        for _, row in df.iterrows():
            # Check if we have valid data
            if row[f'albedo_{list(algorithms_info.keys())[0]}_mean'] is not None:
                comparison_row = {
                    'Glacier': glacier_name,
                    'Date': row['date'],
                    'Cloud_Cover': f"{row['cloud_cover']}%"
                }
                
                # Add albedo values for each algorithm
                for alg_key, alg_info in algorithms_info.items():
                    comparison_row[alg_info['name']] = row[f'albedo_{alg_key}_mean']
                
                comparison_data.append(comparison_row)
    
    # Create DataFrame and display
    comparison_df = pd.DataFrame(comparison_data)
    
    if not comparison_df.empty:
        print("\nALGORITHM COMPARISON TABLE:")
        print(comparison_df.to_string(index=False, float_format='%.3f'))
        
        # Calculate algorithm statistics
        print("\nALGORITHM PERFORMANCE SUMMARY:")
        print("-" * 40)
        
        algorithm_columns = [info['name'] for info in algorithms_info.values()]
        for col in algorithm_columns:
            if col in comparison_df.columns:
                values = comparison_df[col].dropna()
                if len(values) > 0:
                    print(f"{col:<20}: {values.mean():.3f} ± {values.std():.3f} (range: {values.min():.3f}-{values.max():.3f})")
    
    return comparison_df

def main_satellite_albedo_analysis():
    """
    Main function to execute comprehensive satellite albedo analysis.
    This function orchestrates the entire analysis workflow.
    """
    
    print("="*70)
    print("MULTI-ALGORITHM SATELLITE ALBEDO ANALYSIS")
    print("Svalbard Glaciers - July 26 & August 20, 2011")
    print("="*70)
    
    # Initialize Earth Engine
    initialize_earth_engine()
    
    # Step 1: Define study parameters
    print("\nStep 1: Defining study parameters")
    print("-" * 35)
    
    # Target dates for analysis (matching field observations)
    target_dates = ['2011-07-26', '2011-08-20']
    print(f"Target dates: {target_dates}")
    
    # Define glacier geometries
    hansbreen_ee, werenskiold_ee = define_glacier_geometries()
    
    # Step 2: Define albedo algorithms
    print(f"\nStep 2: Defining albedo algorithms")
    print("-" * 36)
    algorithms_info = define_albedo_algorithms()
    
    # Step 3: Retrieve satellite images
    print(f"\nStep 3: Retrieving Landsat images")
    print("-" * 33)
    collection, image_info = get_landsat_images(target_dates)
    
    # Step 4: Process images and calculate albedo
    print(f"\nStep 4: Processing images and calculating albedo")
    print("-" * 47)
    print("This may take several minutes...")
    
    hansbreen_results = []
    werenskiold_results = []
    
    for info in image_info:
        try:
            print(f"  Processing {info['date']} ({info['cloud_cover']}% cloud cover)...")
            
            # Get specific image
            image = collection.filter(ee.Filter.eq('DATE_ACQUIRED', info['date'])).first()
            
            # Calculate statistics for both glaciers
            hansbreen_stats = get_glacier_albedo_statistics(
                image, hansbreen_ee, info['date'], info['cloud_cover'], algorithms_info
            )
            werenskiold_stats = get_glacier_albedo_statistics(
                image, werenskiold_ee, info['date'], info['cloud_cover'], algorithms_info
            )
            
            hansbreen_results.append(hansbreen_stats)
            werenskiold_results.append(werenskiold_stats)
            
        except Exception as e:
            print(f"  ❌ Error processing {info['date']}: {e}")
    
    # Step 5: Convert results to DataFrames
    hansbreen_df = pd.DataFrame(hansbreen_results)
    werenskiold_df = pd.DataFrame(werenskiold_results)
    
    # Step 6: Display detailed results
    print(f"\nStep 5: Analyzing results")
    print("-" * 25)
    display_results(hansbreen_df, werenskiold_df, algorithms_info)
    
    # Step 7: Temporal change analysis
    print(f"\nStep 6: Temporal change analysis")
    print("-" * 33)
    
    for df, glacier_name in [(hansbreen_df, 'Hansbreen'), (werenskiold_df, 'Werenskioldbreen')]:
        changes = analyze_temporal_changes(df, algorithms_info)
        
        if changes:
            print(f"\n{glacier_name.upper()} - TEMPORAL CHANGES:")
            print("-" * 40)
            
            for date_pair, change_data in changes.items():
                print(f"\n{date_pair}:")
                for alg_key, change_info in change_data.items():
                    alg_name = algorithms_info[alg_key]['name']
                    abs_change = change_info['absolute']
                    pct_change = change_info['percent']
                    print(f"  {alg_name:<20}: {abs_change:+.3f} ({pct_change:+.1f}%)")
    
    # Step 8: Algorithm comparison
    print(f"\nStep 7: Algorithm comparison")
    print("-" * 27)
    comparison_df = analyze_algorithm_comparison(hansbreen_df, werenskiold_df, algorithms_info)
    
    # Final summary
    print(f"\n" + "="*70)
    print("ANALYSIS SUMMARY")
    print("="*70)
    print("✓ Multi-algorithm satellite albedo analysis completed")
    print(f"✓ {len(algorithms_info)} different algorithms compared")
    print(f"✓ {len(target_dates)} dates analyzed (July 26 & August 20, 2011)")
    print("✓ Both Hansbreen and Werenskioldbreen glaciers processed")
    print("✓ Enhanced cloud masking applied (preserving snow pixels)")
    print("✓ Temporal change analysis completed")
    
    print(f"\nKey findings:")
    print("- Significant albedo decrease observed from July to August")
    print("- All algorithms show consistent temporal trends")
    print("- Algorithm-specific differences highlight uncertainty ranges")
    print("- Results suitable for validation of spatial albedo models")
    
    return hansbreen_df, werenskiold_df, comparison_df, algorithms_info

# Execute analysis if run as main script
if __name__ == "__main__":
    print("Starting Multi-Algorithm Satellite Albedo Analysis...")
    print("This analysis compares different broadband albedo algorithms using Landsat data")
    print("Target: Svalbard glaciers (Hansbreen & Werenskioldbreen)")
    print("Period: Summer 2011 (July 26 & August 20)\n")
    
    try:
        # Run complete analysis
        hansbreen_results, werenskiold_results, comparison_table, algorithm_specs = main_satellite_albedo_analysis()
        
        print(f"\n🎉 Analysis completed successfully!")
        print(f"Results are available in the following variables:")
        print(f"- hansbreen_results: Hansbreen glacier statistics")
        print(f"- werenskiold_results: Werenskioldbreen glacier statistics") 
        print(f"- comparison_table: Algorithm comparison DataFrame")
        print(f"- algorithm_specs: Algorithm specifications and references")
        
    except Exception as e:
        print(f"\n❌ Analysis failed: {e}")
        print("Common solutions:")
        print("- Ensure Google Earth Engine is properly authenticated")
        print("- Check internet connection")
        print("- Verify project permissions")
        print("- Run the authentication setup script first")
        raise
