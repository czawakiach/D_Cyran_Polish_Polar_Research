"""
Temperature-Dominated Linear Regression Model for Albedo Prediction on Svalbard Glaciers

This script implements an alternative approach emphasizing daily positive temperature
as the primary driver of glacier albedo changes, testing thermal vs. precipitation
process dominance in controlling Arctic glacier surface reflectance.

Key Differences from Snowfall Model:
- Primary feature: 'daily_positive_temp' (thermal energy input)
- Hypothesis: Thermal processes dominate over precipitation processes
- Focus: Cumulative thermal forcing rather than snowfall events

Model Architecture:
- Linear regression with thermal-focused features
- Training: 2010 & 2012 data, Testing: 2011 data
- Season: April 8 - September 4 (extended ablation period)

Features:
- day_of_year: Seasonal thermal patterns
- daily_positive_temp: Primary thermal driver (°C)
- pdd: Cumulative thermal history (degree-days)
- snowfall_probability: Precipitation comparison

Dependencies: pandas, numpy, scikit-learn, matplotlib
"""

import pandas as pd
import numpy as np
from pathlib import Path
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_squared_error
from sklearn.impute import SimpleImputer
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime

def load_and_combine_data(train_files, test_files):
    """
    Load and combine meteorological datasets for thermal-focused albedo modeling.
    
    Parameters:
    train_files (list): Training data file paths
    test_files (list): Testing data file paths
    
    Returns:
    tuple: (train_df, test_df) with thermal variable validation
    """
    print("\n" + "="*50)
    print("LOADING THERMAL-FOCUSED DATASETS")
    print("="*50)
    
    # Load training datasets
    train_dfs = []
    for file_path in train_files:
        try:
            df = pd.read_csv(file_path)
            print(f"✓ Loaded training: {file_path} ({len(df)} records)")
            
            # Verify thermal columns
            required_thermal_cols = ['daily_positive_temp', 'pdd']
            missing_cols = [col for col in required_thermal_cols if col not in df.columns]
            if missing_cols:
                print(f"  Warning: Missing thermal columns: {missing_cols}")
            
            train_dfs.append(df)
        except FileNotFoundError:
            print(f"✗ Training file not found: {file_path}")
        except Exception as e:
            print(f"✗ Error loading: {file_path}: {e}")
    
    # Load testing datasets
    test_dfs = []
    for file_path in test_files:
        try:
            df = pd.read_csv(file_path)
            print(f"✓ Loaded testing: {file_path} ({len(df)} records)")
            
            # Report thermal data range
            if 'daily_positive_temp' in df.columns:
                temp_stats = df['daily_positive_temp'].describe()
                print(f"  Daily positive temp range: {temp_stats['min']:.1f} to {temp_stats['max']:.1f}°C")
            
            test_dfs.append(df)
        except FileNotFoundError:
            print(f"✗ Testing file not found: {file_path}")
        except Exception as e:
            print(f"✗ Error loading: {file_path}: {e}")
    
    # Combine datasets
    train_combined = pd.concat(train_dfs, ignore_index=True) if train_dfs else pd.DataFrame()
    test_combined = pd.concat(test_dfs, ignore_index=True) if test_dfs else pd.DataFrame()
    
    print(f"\nDataset Summary:")
    print(f"  Training records: {len(train_combined)}")
    print(f"  Testing records: {len(test_combined)}")
    
    return train_combined, test_combined

def filter_season(df, year_col='year', doy_col='day_of_year'):
    """
    Apply seasonal filtering optimized for thermal albedo processes.
    
    Extended ablation season (April 8 - September 4) captures maximum
    thermal forcing period when temperature effects dominate albedo changes.
    
    Parameters:
    df (pd.DataFrame): Input dataset
    year_col (str): Year column name
    doy_col (str): Day of year column name
    
    Returns:
    pd.DataFrame: Seasonally filtered dataset
    """
    spring_start_doy = 98   # April 8 - onset of thermal forcing
    end_date_doy = 247      # September 4 - end of significant solar input
    
    # Apply seasonal mask
    season_mask = (df[doy_col] >= spring_start_doy) & (df[doy_col] <= end_date_doy)
    filtered_df = df[season_mask].copy()
    
    print(f"\nThermal Season Filtering:")
    print(f"  Original: {len(df)} → Filtered: {len(filtered_df)} records ({len(filtered_df)/len(df)*100:.1f}%)")
    print(f"  Season: Day {spring_start_doy} (Apr 8) → Day {end_date_doy} (Sep 4)")
    
    # Report thermal characteristics
    if 'daily_positive_temp' in filtered_df.columns:
        thermal_stats = filtered_df['daily_positive_temp'].describe()
        print(f"  Thermal range: {thermal_stats['min']:.1f}°C to {thermal_stats['max']:.1f}°C")
        print(f"  Mean daily positive temp: {thermal_stats['mean']:.1f}°C")
    
    return filtered_df

def prepare_data(train_files, test_files):
    """
    Comprehensive data preparation for temperature-dominated albedo prediction.
    
    Workflow:
    1. Load datasets with thermal variable validation
    2. Apply seasonal filtering for optimal thermal signal
    3. Define thermal-focused feature set
    4. Handle missing values with mean imputation
    
    Parameters:
    train_files (list): Training data paths
    test_files (list): Testing data paths
    
    Returns:
    tuple: X_train, X_test, y_train, y_test, test_df (cleaned datasets)
    """
    # Load datasets with thermal validation
    train_df, test_df = load_and_combine_data(train_files, test_files)
    
    # Apply thermal season filtering
    train_df = filter_season(train_df)
    test_df = filter_season(test_df)
    
    # Define thermal-focused feature set
    feature_cols = [
        'day_of_year',          # Seasonal thermal patterns
        'daily_positive_temp',  # PRIMARY: Daily thermal energy input
        'pdd',                  # Cumulative thermal history
        'snowfall_probability'  # Precipitation comparison
    ]
    
    print(f"\nThermal Feature Set:")
    for i, feature in enumerate(feature_cols, 1):
        if feature == 'daily_positive_temp':
            print(f"  {i}. {feature} ← PRIMARY THERMAL DRIVER")
        elif feature == 'pdd':
            print(f"  {i}. {feature} ← Thermal memory/history")
        elif feature == 'snowfall_probability':
            print(f"  {i}. {feature} ← Precipitation comparison")
        else:
            print(f"  {i}. {feature} ← Seasonal patterns")
    
    # Extract features and targets
    X_train = train_df[feature_cols]
    y_train = train_df['albedo']
    X_test = test_df[feature_cols]
    y_test = test_df['albedo']
    
    # Handle missing values with mean imputation
    feature_imputer = SimpleImputer(strategy='mean')
    target_imputer = SimpleImputer(strategy='mean')
    
    # Transform datasets
    X_train_clean = pd.DataFrame(
        feature_imputer.fit_transform(X_train),
        columns=X_train.columns, index=X_train.index
    )
    X_test_clean = pd.DataFrame(
        feature_imputer.transform(X_test),
        columns=X_test.columns, index=X_test.index
    )
    
    y_train_clean = pd.Series(
        target_imputer.fit_transform(y_train.values.reshape(-1, 1)).ravel(),
        index=y_train.index
    )
    y_test_clean = pd.Series(
        target_imputer.transform(y_test.values.reshape(-1, 1)).ravel(),
        index=y_test.index
    )
    
    # Data quality assessment
    print(f"\nThermal Data Quality Assessment:")
    print(f"  Training samples: {len(X_train_clean)}")
    print(f"  Testing samples: {len(X_test_clean)}")
    
    missing_train = X_train.isna().sum()
    for feature, missing_count in missing_train.items():
        if missing_count > 0:
            pct_missing = missing_count / len(X_train) * 100
            print(f"  {feature} missing: {missing_count} ({pct_missing:.1f}%)")
    
    # Thermal statistics
    if 'daily_positive_temp' in X_train_clean.columns:
        thermal_stats = X_train_clean['daily_positive_temp'].describe()
        print(f"\nThermal Statistics (Training):")
        print(f"  Mean daily positive temp: {thermal_stats['mean']:.2f}°C ± {thermal_stats['std']:.2f}°C")
        print(f"  Range: {thermal_stats['min']:.1f} to {thermal_stats['max']:.1f}°C")
    
    return X_train_clean, X_test_clean, y_train_clean, y_test_clean, test_df

def train_and_evaluate_model(X_train, X_test, y_train, y_test, test_data):
    """
    Train and evaluate temperature-dominated linear regression model.
    
    Evaluation focuses on:
    - Overall performance metrics
    - Thermal vs. precipitation feature importance
    - Station-specific performance analysis
    - Physical interpretation of thermal coefficients
    
    Parameters:
    X_train, X_test (pd.DataFrame): Feature matrices
    y_train, y_test (pd.Series): Target vectors
    test_data (pd.DataFrame): Original test data
    
    Returns:
    tuple: model, predictions, metrics, feature_importance
    """
    print("\n" + "="*50)
    print("TEMPERATURE-DOMINATED MODEL TRAINING")
    print("="*50)
    
    # Train thermal-focused linear regression
    model = LinearRegression()
    print("Training temperature-dominated linear regression...")
    print("Primary hypothesis: Daily positive temperature drives albedo changes")
    
    model.fit(X_train, y_train)
    
    # Generate predictions
    y_pred = model.predict(X_test)
    print("Generating thermal-based albedo predictions...")
    
    # Calculate performance metrics
    r2 = r2_score(y_test, y_pred)
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    mae = np.mean(np.abs(y_test - y_pred))
    
    print(f"\nThermal Model Performance:")
    print(f"  R² Score: {r2:.3f}")
    print(f"  RMSE: {rmse:.3f}")
    print(f"  MAE: {mae:.3f}")
    
    # Station-specific performance
    station_metrics = {}
    print(f"\nStation-Specific Performance:")
    
    for station in test_data['station'].unique():
        station_mask = test_data['station'] == station
        station_y_test = y_test[station_mask]
        station_y_pred = y_pred[station_mask]
        
        if len(station_y_test) > 1:
            station_r2 = r2_score(station_y_test, station_y_pred)
            station_rmse = np.sqrt(mean_squared_error(station_y_test, station_y_pred))
            station_mae = np.mean(np.abs(station_y_test - station_y_pred))
            
            station_metrics[station] = {
                'R2': station_r2, 'RMSE': station_rmse, 'MAE': station_mae,
                'n_samples': len(station_y_test)
            }
            
            performance = "Excellent" if station_r2 > 0.7 else "Good" if station_r2 > 0.5 else "Moderate"
            print(f"  {station}: R² = {station_r2:.3f} ({performance}), n = {len(station_y_test)}")
    
    # Feature importance analysis
    feature_importance = dict(zip(X_train.columns, model.coef_))
    
    # Calculate normalized importance
    abs_coefficients = np.abs(model.coef_)
    normalized_importance = abs_coefficients / np.sum(abs_coefficients)
    normalized_importance = dict(zip(X_train.columns, normalized_importance))
    
    # Process dominance assessment
    thermal_features = ['daily_positive_temp', 'pdd']
    thermal_importance = sum(normalized_importance.get(f, 0) for f in thermal_features)
    precip_importance = normalized_importance.get('snowfall_probability', 0)
    
    print(f"\nProcess Dominance Assessment:")
    print(f"  Thermal processes: {thermal_importance:.1%}")
    print(f"  Precipitation processes: {precip_importance:.1%}")
    
    if thermal_importance > precip_importance:
        print(f"  → THERMAL DOMINANCE confirmed")
    else:
        print(f"  → PRECIPITATION DOMINANCE detected")
    
    print(f"\nFeature Analysis:")
    print(f"  Model Intercept: {model.intercept_:.3f}")
    
    for feature in X_train.columns:
        coef = feature_importance[feature]
        norm_imp = normalized_importance[feature]
        
        # Physical interpretation
        if feature == 'daily_positive_temp':
            interpretation = "MORE heat → LOWER albedo (melting)" if coef < 0 else "MORE heat → HIGHER albedo (unexpected)"
        elif feature == 'pdd':
            interpretation = "MORE cumulative heat → LOWER albedo" if coef < 0 else "MORE cumulative heat → HIGHER albedo"
        elif feature == 'snowfall_probability':
            interpretation = "MORE snowfall → HIGHER albedo" if coef > 0 else "MORE snowfall → LOWER albedo"
        else:
            interpretation = "Later season → LOWER albedo" if coef < 0 else "Later season → HIGHER albedo"
        
        print(f"  {feature}:")
        print(f"    Coefficient: {coef:+.3f}, Importance: {norm_imp:.1%}")
        print(f"    Physical meaning: {interpretation}")
    
    return model, y_pred, r2, rmse, station_metrics, feature_importance, normalized_importance

def plot_predicted_vs_measured(y_test, y_pred, test_data):
    """
    Create scatter plot for temperature-dominated albedo predictions.
    
    Features station-wise color coding and thermal model performance metrics.
    
    Parameters:
    y_test (array): Observed albedo values
    y_pred (array): Temperature-model predictions
    test_data (pd.DataFrame): Test dataset with station info
    """
    plt.figure(figsize=(10, 8))
    
    # Station-wise plotting with enhanced styling
    colors = ['#2E86AB', '#A23B72', '#F18F01', '#C73E1D', '#6A994E']
    markers = ['o', 's', '^', 'D', 'v']
    
    for i, station in enumerate(test_data['station'].unique()):
        station_mask = test_data['station'] == station
        color = colors[i % len(colors)]
        marker = markers[i % len(markers)]
        
        plt.scatter(y_test[station_mask], y_pred[station_mask], 
                   alpha=0.7, s=60, color=color, marker=marker,
                   label=f'{station.upper()}', 
                   edgecolors='white', linewidth=1)
    
    # Perfect prediction reference line
    min_val = min(min(y_test), min(y_pred))
    max_val = max(max(y_test), max(y_pred))
    line_range = np.linspace(min_val, max_val, 100)
    plt.plot(line_range, line_range, 'k--', alpha=0.8, linewidth=2.5, 
             label='Perfect Prediction (1:1)', zorder=1)
    
    # Performance metrics annotation
    r2_overall = r2_score(y_test, y_pred)
    rmse_overall = np.sqrt(mean_squared_error(y_test, y_pred))
    
    textstr = f'Temperature-Dominated Model\nR² = {r2_overall:.3f}\nRMSE = {rmse_overall:.3f}'
    props = dict(boxstyle='round,pad=0.5', facecolor='lightblue', alpha=0.8)
    plt.text(0.05, 0.95, textstr, transform=plt.gca().transAxes, 
             fontsize=12, fontweight='bold', verticalalignment='top', bbox=props)
    
    # Formatting
    plt.xlabel('Measured Albedo', fontweight='bold', fontsize=12)
    plt.ylabel('Predicted Albedo\n(Temperature-Dominated Model)', fontweight='bold', fontsize=12)
    plt.title('Temperature-Dominated Albedo Prediction Validation\n'
              'Daily Positive Temperature as Primary Driver (2011 Test Data)', 
              fontweight='bold', fontsize=14)
    
    plt.legend(loc='lower right', framealpha=0.9)
    plt.grid(True, alpha=0.3)
    plt.axis('equal')
    
    margin = (max_val - min_val) * 0.05
    plt.xlim(min_val - margin, max_val + margin)
    plt.ylim(min_val - margin, max_val + margin)
    
    plt.tight_layout()
    plt.show()

def plot_feature_importance(feature_importance):
    """
    Visualize thermal vs. precipitation feature importance.
    
    Color-codes features by process type (thermal vs precipitation vs seasonal)
    with enhanced annotations for thermal interpretation.
    
    Parameters:
    feature_importance (dict): Feature coefficients
    """
    plt.figure(figsize=(12, 7))
    
    # Prepare plotting data
    importance_df = pd.DataFrame({
        'Feature': list(feature_importance.keys()),
        'Coefficient': list(feature_importance.values())
    })
    
    # Sort by absolute coefficient value
    importance_df = importance_df.sort_values('Coefficient', key=abs, ascending=True)
    
    # Process-based color scheme
    colors = []
    for feature in importance_df['Feature']:
        if feature in ['daily_positive_temp', 'pdd']:
            colors.append('#FF6B35')  # Orange-red for thermal
        elif feature == 'snowfall_probability':
            colors.append('#004E89')  # Blue for precipitation
        else:
            colors.append('#7209B7')  # Purple for seasonal
    
    # Create horizontal bar plot
    bars = plt.barh(importance_df['Feature'], importance_df['Coefficient'], 
                   color=colors, alpha=0.8, edgecolor='white', linewidth=1)
    
    # Add coefficient annotations
    for i, (feature, coef) in enumerate(zip(importance_df['Feature'], importance_df['Coefficient'])):
        text_x = coef + (0.002 if coef >= 0 else -0.002)
        ha = 'left' if coef >= 0 else 'right'
        
        plt.text(text_x, i, f'{coef:+.3f}', 
                ha=ha, va='center', fontweight='bold', fontsize=11)
    
    # Formatting
    plt.xlabel('Regression Coefficient', fontweight='bold', fontsize=12)
    plt.ylabel('Features', fontweight='bold', fontsize=12)
    plt.title('Temperature-Dominated Model: Feature Importance\n'
              'Thermal vs. Precipitation Process Contributions', 
              fontweight='bold', fontsize=14)
    
    plt.grid(True, alpha=0.3, axis='x')
    plt.axvline(x=0, color='black', linestyle='-', alpha=0.7, linewidth=1)
    
    # Custom legend for process types
    from matplotlib.patches import Patch
    legend_elements = [
        Patch(facecolor='#FF6B35', alpha=0.8, label='Thermal Processes'),
        Patch(facecolor='#004E89', alpha=0.8, label='Precipitation Processes'),
        Patch(facecolor='#7209B7', alpha=0.8, label='Seasonal Patterns')
    ]
    plt.legend(handles=legend_elements, loc='lower right')
    
    plt.tight_layout()
    plt.show()

def plot_station_time_series(station_name, test_data, y_test, y_pred):
    """
    Create temporal validation plot for temperature-dominated predictions.
    
    Shows measured vs. predicted albedo time series with thermal model
    performance metrics and monthly temporal reference.
    
    Parameters:
    station_name (str): Station identifier
    test_data (pd.DataFrame): Original temporal dataset
    y_test (array): Observed albedo values
    y_pred (array): Temperature-model predictions
    """
    # Extract station data
    station_mask = test_data['station'] == station_name
    
    if not station_mask.any():
        print(f"Warning: No thermal data found for station {station_name}")
        return
    
    station_data = test_data[station_mask].copy()
    station_measured = y_test[station_mask]
    station_predicted = y_pred[station_mask]
    
    # Sort by temporal order
    sort_indices = np.argsort(station_data['day_of_year'].values)
    days_sorted = station_data['day_of_year'].values[sort_indices]
    measured_sorted = station_measured.values[sort_indices]
    predicted_sorted = station_predicted[sort_indices]
    
    # Calculate performance metrics
    station_r2 = r2_score(station_measured, station_predicted)
    station_rmse = np.sqrt(mean_squared_error(station_measured, station_predicted))
    station_mae = np.mean(np.abs(station_measured - station_predicted))
    
    # Create time series plot
    plt.figure(figsize=(14, 8))
    
    # Plot measured and predicted albedo
    plt.plot(days_sorted, measured_sorted, 'b-', linewidth=3, 
             label='Measured Albedo', alpha=0.9, marker='o', markersize=5,
             markerfacecolor='white', markeredgecolor='blue', markeredgewidth=1.5)
    
    plt.plot(days_sorted, predicted_sorted, 'r--', linewidth=2.5, 
             label='Temperature-Model Prediction', alpha=0.9, marker='s', markersize=4,
             markerfacecolor='red', markeredgecolor='darkred', markeredgewidth=1)
    
    # Add prediction error shading
    plt.fill_between(days_sorted, measured_sorted, predicted_sorted, 
                     alpha=0.25, color='gray', label='Prediction Error Zone')
    
    # Performance metrics annotation
    textstr = (f'Temperature-Dominated Model\n'
               f'R² = {station_r2:.3f}\n'
               f'RMSE = {station_rmse:.3f}\n'
               f'MAE = {station_mae:.3f}\n'
               f'Samples = {len(station_measured)}')
    props = dict(boxstyle='round,pad=0.5', facecolor='wheat', alpha=0.9, edgecolor='orange')
    plt.text(0.02, 0.98, textstr, transform=plt.gca().transAxes, fontsize=12,
             verticalalignment='top', bbox=props, fontweight='bold')
    
    # Formatting
    plt.xlabel('Day of Year', fontweight='bold', fontsize=12)
    plt.ylabel('Surface Albedo', fontweight='bold', fontsize=12)
    plt.title(f'Temperature-Dominated Albedo Prediction: {station_name.upper()}\n'
              f'Daily Positive Temperature Model Validation (2011)', 
              fontweight='bold', fontsize=14)
    
    plt.legend(loc='upper right', framealpha=0.9)
    plt.grid(True, alpha=0.3)
    plt.ylim(0, 1)
    
    # Add monthly reference
    month_days = [98, 121, 152, 182, 213, 244]
    month_labels = ['Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep']
    
    valid_months = [(day, label) for day, label in zip(month_days, month_labels) 
                   if min(days_sorted) <= day <= max(days_sorted)]
    
    if valid_months:
        valid_days, valid_labels = zip(*valid_months)
        plt.xticks(valid_days, valid_labels)
        
        # Add month separators
        for day in valid_days:
            plt.axvline(x=day, color='gray', linestyle=':', alpha=0.5)
    
    plt.tight_layout()
    plt.show()

def main():
    """
    Main execution function for temperature-dominated albedo prediction analysis.
    
    Tests the hypothesis that daily positive temperature is superior to snowfall
    probability for predicting glacier albedo changes, representing thermal
    process dominance over precipitation processes.
    
    Workflow:
    1. Load datasets with thermal variable validation
    2. Train temperature-dominated linear regression
    3. Evaluate thermal vs. precipitation importance
    4. Generate comprehensive visualizations
    5. Assess thermal dominance hypothesis
    """
    print("="*70)
    print("TEMPERATURE-DOMINATED GLACIER ALBEDO PREDICTION MODEL")
    print("Thermal Process Emphasis vs. Precipitation Controls")
    print("="*70)
    print(f"Analysis started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # Research hypothesis
    print(f"\nRESEARCH HYPOTHESIS:")
    print(f"  Daily positive temperature is superior to snowfall probability")
    print(f"  for predicting glacier albedo, indicating thermal process")
    print(f"  dominance over precipitation processes in Arctic glaciers.")
    
    # Dataset configuration with temporal separation
    train_files = [
        "hans4_2010_processed_with_pdd.csv",      # Hansbreen lower - thermal baseline
        "hans9_2010_processed_with_pdd.csv",      # Hansbreen upper - elevation gradient
        "werenskiold_2012_processed_with_pdd.csv", # Werenskiöldbreen - spatial validation
    ]
    
    test_files = [
        "hans4_2011_processed_with_pdd.csv",      # Independent validation year
        "werenskiold_2011_processed_with_pdd.csv"
    ]
    
    print(f"\nDataset Configuration:")
    print(f"  Training: Multi-year thermal calibration")
    print(f"  Testing: Independent year validation (2011)")
    
    # Data preparation pipeline
    print(f"\n{'-'*50}")
    print("THERMAL DATA PREPARATION")
    print(f"{'-'*50}")
    
    X_train_clean, X_test_clean, y_train_clean, y_test_clean, test_data_clean = prepare_data(
        train_files, test_files
    )
    
    # Verify data availability
    if len(X_train_clean) == 0 or len(X_test_clean) == 0:
        print("ERROR: Insufficient data. Check file paths and thermal variables.")
        return
    
    # Model training and evaluation
    model, y_pred, r2, rmse, station_metrics, feature_importance, normalized_importance = train_and_evaluate_model(
        X_train_clean, X_test_clean, y_train_clean, y_test_clean, test_data_clean
    )
    
    # Thermal dominance hypothesis testing
    print(f"\n{'-'*50}")
    print("THERMAL DOMINANCE HYPOTHESIS EVALUATION")
    print(f"{'-'*50}")
    
    thermal_features = ['daily_positive_temp', 'pdd']
    thermal_importance = sum(normalized_importance.get(f, 0) for f in thermal_features)
    precip_importance = normalized_importance.get('snowfall_probability', 0)
    
    print(f"Process Contribution Analysis:")
    print(f"  Thermal Processes: {thermal_importance:.1%}")
    print(f"  Precipitation Processes: {precip_importance:.1%}")
    
    # Hypothesis test results
    if thermal_importance > precip_importance:
        dominance_ratio = thermal_importance / precip_importance if precip_importance > 0 else float('inf')
        print(f"  ✓ THERMAL DOMINANCE CONFIRMED")
        print(f"    Thermal processes {dominance_ratio:.1f}x more important")
    else:
        dominance_ratio = precip_importance / thermal_importance if thermal_importance > 0 else float('inf')
        print(f"  ✗ PRECIPITATION DOMINANCE PERSISTS")
        print(f"    Precipitation processes {dominance_ratio:.1f}x more important")
    
    # Performance assessment
    performance = "EXCELLENT" if r2 >= 0.7 else "GOOD" if r2 >= 0.5 else "MODERATE" if r2 >= 0.3 else "POOR"
    print(f"\nModel Performance: {performance} (R² = {r2:.3f})")
    
    # Results summary
    print(f"\n{'='*70}")
    print("TEMPERATURE-DOMINATED MODEL: FINAL RESULTS")
    print(f"{'='*70}")
    
    print(f"Overall Performance: R² = {r2:.3f}, RMSE = {rmse:.3f}")
    
    print(f"\nStation-Specific Results:")
    for station, metrics in station_metrics.items():
        print(f"  {station}: R² = {metrics['R2']:.3f}, RMSE = {metrics['RMSE']:.3f}, n = {metrics['n_samples']}")
    
    print(f"\nThermal Feature Analysis:")
    for feature in ['daily_positive_temp', 'pdd']:
        if feature in feature_importance:
            coef = feature_importance[feature]
            importance = normalized_importance[feature]
            expected = "negative (thermal energy → melting)"
            actual = "negative" if coef < 0 else "positive"
            match = "✓ expected" if coef < 0 else "⚠ unexpected"
            
            print(f"  {feature}: coeff = {coef:+.3f} ({actual}) {match}, importance = {importance:.1%}")
    
    # Generate visualizations
    print(f"\n{'-'*50}")
    print("GENERATING THERMAL MODEL VISUALIZATIONS")
    print(f"{'-'*50}")
    
    print("Creating predicted vs. measured scatter plot...")
    plot_predicted_vs_measured(y_test_clean, y_pred, test_data_clean)
    
    print("Creating thermal feature importance plot...")
    plot_feature_importance(feature_importance)
    
    print("Creating station-specific time series plots...")
    for station in test_data_clean['station'].unique():
        print(f"  Plotting thermal validation for {station}...")
        plot_station_time_series(station, test_data_clean, y_test_clean, y_pred)
    
    # Research recommendations
    print(f"\n{'-'*50}")
    print("RESEARCH RECOMMENDATIONS")
    print(f"{'-'*50}")
    
    if r2 > 0.6 and thermal_importance > 0.4:
        print(f"  ✓ STRONG validation of thermal control hypothesis")
        print(f"  → Daily positive temperature is excellent albedo predictor")
    elif r2 > 0.4 and thermal_importance > 0.3:
        print(f"  ✓ MODERATE validation of thermal control hypothesis")
        print(f"  → Consider hybrid thermal-precipitation models")
    else:
        print(f"  ⚠ LIMITED validation of thermal control hypothesis")
        print(f"  → Snowfall probability may remain superior approach")
    
    print(f"\nNext Steps:")
    print(f"  1. Compare directly with snowfall-dominated model")
    print(f"  2. Develop hybrid thermal-precipitation approach")
    print(f"  3. Test non-linear thermal relationships")
    print(f"  4. Extend validation to additional years")
    print(f"  5. Investigate seasonal thermal sub-patterns")
    
    print(f"\n{'='*70}")
    print(f"Temperature-dominated analysis completed: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"{'='*70}")

if __name__ == "__main__":
    """Execute complete temperature-dominated albedo analysis."""
    main()
